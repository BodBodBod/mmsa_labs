{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec90014a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (500, 8) y.shape: (500,)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 76\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# сортируем по метрике (для регрессии — по rmse возрастанию; для классификации — по logloss возрастанию)\u001b[39;00m\n\u001b[32m     74\u001b[39m results_uni.sort(key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m1\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m best_uni = \u001b[43mresults_uni\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest univariate feature:\u001b[39m\u001b[33m\"\u001b[39m, best_uni[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mmetric:\u001b[39m\u001b[33m\"\u001b[39m, best_uni[\u001b[32m1\u001b[39m])\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# %% [markdown]\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# Блок 6: CV для мультивариативных моделей\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Model Comparison Notebook\n",
    "# Цель: выбрать лучшую модель из унивариативного и мультивариативного набора,\n",
    "# выполнить приближённый байесовский анализ (BIC → Bayes Factor), классические тесты,\n",
    "# визуализации и краткий отчёт.\n",
    "\n",
    "# %% [code]\n",
    "# Блок 1: библиотеки\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score, log_loss, accuracy_score\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import ttest_rel, wilcoxon\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "df = pd.read_csv('forestfires.csv')\n",
    "X = df.drop(columns=['area'])\n",
    "y = df['area']\n",
    "\n",
    "# Для демонстрации сгенерируем синтетические данные (регрессия)\n",
    "from sklearn.datasets import make_regression, make_classification\n",
    "\n",
    "X, y = make_regression(n_samples=500, n_features=8, n_informative=4, noise=10, random_state=0)\n",
    "X = pd.DataFrame(X, columns=[f'x{i}' for i in range(X.shape[1])])\n",
    "y = pd.Series(y, name='area')\n",
    "\n",
    "\n",
    "print(\"X.shape:\", X.shape, \"y.shape:\", y.shape)\n",
    "\n",
    "# %% [markdown]\n",
    "# Блок 3: Настройка CV и кандидатов моделей\n",
    "K = 5\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=0)\n",
    "\n",
    "# Унивариативный кандидат: лучший отдельный признак (по CV metric)\n",
    "# Мультивариативные кандидаты: линейная и случайный лес\n",
    "multi_models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "}\n",
    "\n",
    "# %% [markdown]\n",
    "# Блок 4: Функции для CV и метрик\n",
    "def cv_metrics_regression(model, X, y, kf):\n",
    "    metrics = []\n",
    "    preds = []\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        model.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
    "        yhat = pd.Series(model.predict(X.iloc[test_idx]), index=test_idx)\n",
    "        rmse = np.sqrt(mean_squared_error(y.iloc[test_idx], yhat))\n",
    "        r2 = r2_score(y.iloc[test_idx], yhat)\n",
    "        metrics.append({'rmse': rmse, 'r2': r2})\n",
    "        preds.append((test_idx, yhat))\n",
    "    return pd.DataFrame(metrics), preds\n",
    "\n",
    "# Блок 5: Найдём лучший одиночный признак\n",
    "results_uni = []\n",
    "for col in X.columns:\n",
    "    X_col = X[[col]]\n",
    "    model = LinearRegression()\n",
    "    df_metrics, _ = cv_metrics_regression(model, X_col, y, kf)\n",
    "    results_uni.append((col, df_metrics['rmse'].mean(), df_metrics['rmse'].std(), df_metrics))\n",
    "\n",
    "results_uni.sort(key=lambda x: x[1])   # сортируем по mean RMSE (меньше лучше)\n",
    "\n",
    "best_uni = results_uni[0]\n",
    "print(\"Best univariate feature:\", best_uni[0], \"mean_rmse:\", best_uni[1], \"std_rmse:\", best_uni[2])\n",
    "\n",
    "# Блок 6: CV для мультивариативных моделей\n",
    "multi_metrics = {}\n",
    "for name, model in multi_models.items():\n",
    "    metrics_df, preds = cv_metrics_regression(model, X, y, kf)\n",
    "    multi_metrics[name] = {'metrics': metrics_df, 'preds': preds}\n",
    "    print(name, \"mean metrics:\\n\", metrics_df.mean().to_dict())\n",
    "\n",
    "# %% [markdown]\n",
    "# Блок 7: Рассчитаем BIC / log-likelihood для параметрических моделей (statsmodels)\n",
    "# Для регрессии: линейная модель через OLS (на всех данных)\n",
    "bic_dict = {}\n",
    "\n",
    "X_sm = sm.add_constant(X)  # включает константу\n",
    "ols = sm.OLS(y, X_sm).fit()\n",
    "bic_dict['OLS_full'] = {'bic': float(ols.bic), 'llf': float(ols.llf), 'k': int(ols.df_model + 1)}\n",
    "# Для лучшего унивариативного признака:\n",
    "col = best_uni[0]\n",
    "X_sm_uni = sm.add_constant(X[[col]])\n",
    "ols_uni = sm.OLS(y, X_sm_uni).fit()\n",
    "bic_dict['OLS_uni'] = {'bic': float(ols_uni.bic), 'llf': float(ols_uni.llf), 'k': int(ols_uni.df_model + 1)}\n",
    "print(\"BIC OLS full:\", bic_dict['OLS_full'])\n",
    "print(\"BIC OLS uni :\", bic_dict['OLS_uni'])\n",
    "\n",
    "# %% [markdown]\n",
    "# Блок 8: Bayes Factor (приближённо через разницу BIC)\n",
    "# BF_{1 over 2} ≈ exp((BIC2 - BIC1)/2)\n",
    "def bayes_factor_from_bic(bic1, bic2):\n",
    "    return np.exp((bic2 - bic1) / 2.0)\n",
    "\n",
    "# Считаем BF между OLS_full и OLS_uni (если есть)\n",
    "if ('OLS_full' in bic_dict) and ('OLS_uni' in bic_dict):\n",
    "    bic1 = bic_dict['OLS_uni']['bic']\n",
    "    bic2 = bic_dict['OLS_full']['bic']\n",
    "    bf = bayes_factor_from_bic(bic1, bic2)  # BF uni over full\n",
    "    print(f\"BF (uni over full) ≈ {bf:.3g}\")\n",
    "    # интерпретация по Джеффриса\n",
    "    def interpret_bf(bf):\n",
    "        if bf < 1/100:\n",
    "            return \"Очень сильная поддержка модели 2 (Full)\"\n",
    "        if bf < 1/10:\n",
    "            return \"Сильная поддержка модели 2 (Full)\"\n",
    "        if bf < 1/3:\n",
    "            return \"Умеренная поддержка модели 2 (Full)\"\n",
    "        if bf < 1:\n",
    "            return \"Слабая поддержка модели 2 (Full)\"\n",
    "        if bf == 1:\n",
    "            return \"Нет различий\"\n",
    "        if bf <= 3:\n",
    "            return \"Слабая поддержка модели 1 (Uni)\"\n",
    "        if bf <= 10:\n",
    "            return \"Умеренная поддержка модели 1 (Uni)\"\n",
    "        if bf <= 30:\n",
    "            return \"Сильная поддержка модели 1 (Uni)\"\n",
    "        return \"Очень сильная поддержка модели 1 (Uni)\"\n",
    "    print(\"Интерпретация:\", interpret_bf(bf))\n",
    "\n",
    "# %% [markdown]\n",
    "# Блок 9: Статистические парные тесты по CV метрикам\n",
    "# Сравним лучшую унивариативную модель и каждую мульти-модель по распределениям метрик\n",
    "# Соберём векторы метрик (по fold) для сравнения\n",
    "# лучший uni: получить его CV метрики (we stored df in best_uni[3])\n",
    "uni_metrics_df = best_uni[3]  # DataFrame с K метриками\n",
    "for name, info in multi_metrics.items():\n",
    "    multi_df = info['metrics']\n",
    "    # используем RMSE сравнение: uni rmse vs multi rmse\n",
    "    try:\n",
    "        uni_vec = uni_metrics_df['rmse'].values\n",
    "        multi_vec = multi_df['rmse'].values\n",
    "        # парный t-test\n",
    "        t_stat, p_val = ttest_rel(uni_vec, multi_vec)\n",
    "        # wilcoxon (если не нормальное)\n",
    "        try:\n",
    "            w_stat, w_p = wilcoxon(uni_vec, multi_vec)\n",
    "        except Exception:\n",
    "            w_stat, w_p = (np.nan, np.nan)\n",
    "        print(f\"Compare UNI({best_uni[0]}) vs {name}: t_p={p_val:.4f}, wilcoxon_p={w_p}\")\n",
    "    except Exception as e:\n",
    "        print(\"Compare failed:\", e)\n",
    "\n",
    "# %% [markdown]\n",
    "# Блок 10: Визуализации распределений метрик (boxplot / violin)\n",
    "plt.figure(figsize=(10,6))\n",
    "plot_df = []\n",
    "\n",
    "for i,val in enumerate(uni_metrics_df['rmse']):\n",
    "    plot_df.append({'model': f'UNI:{best_uni[0]}', 'fold': i, 'metric': val})\n",
    "for name, info in multi_metrics.items():\n",
    "    for i,val in enumerate(info['metrics']['rmse']):\n",
    "        plot_df.append({'model': name, 'fold': i, 'metric': val})\n",
    "\n",
    "\n",
    "plot_df = pd.DataFrame(plot_df)\n",
    "sns.boxplot(x='model', y='metric', data=plot_df)\n",
    "sns.swarmplot(x='model', y='metric', data=plot_df, color='0.25', alpha=0.8)\n",
    "plt.title('Metric distributions by model (lower is better)')\n",
    "plt.xticks(rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# Блок 11: Таблица сравнения (mean ± std), BIC и BF где применимо\n",
    "rows = []\n",
    "\n",
    "rows.append({\n",
    "    'model': f'UNI:{best_uni[0]}',\n",
    "    'mean_metric': uni_metrics_df['rmse'].mean(),\n",
    "    'std_metric': uni_metrics_df['rmse'].std(),\n",
    "    'bic': bic_dict.get('OLS_uni', {}).get('bic', np.nan)\n",
    "})\n",
    "\n",
    "for name, info in multi_metrics.items():\n",
    "    dfm = info['metrics']\n",
    "    key = 'rmse'\n",
    "    rows.append({\n",
    "        'model': name,\n",
    "        'mean_metric': dfm[key].mean(),\n",
    "        'std_metric': dfm[key].std(),\n",
    "        'bic': bic_dict.get('OLS_full', {}).get('bic', np.nan)\n",
    "    })\n",
    "\n",
    "comp_df = pd.DataFrame(rows).sort_values('mean_metric')\n",
    "display(comp_df)\n",
    "\n",
    "# %% [markdown]\n",
    "# Блок 12: Краткий автоматический отчёт (строки, которые можно сохранить в файл)\n",
    "report = []\n",
    "report.append(\"INTRODUCTION\")\n",
    "report.append(f\"Data shape: X={X.shape}, y={y.shape}\")\n",
    "report.append(\"\\nPERFORMANCE SUMMARY\")\n",
    "report.append(comp_df.to_string(index=False))\n",
    "# BF summary\n",
    "if len(bic_dict) >= 2:\n",
    "    report.append(\"\\nBIC values:\")\n",
    "    for k,v in bic_dict.items():\n",
    "        report.append(f\"{k}: bic={v['bic']}, llf={v['llf']}\")\n",
    "    if 'OLS_uni' in bic_dict and 'OLS_full' in bic_dict:\n",
    "        bf_val = bayes_factor_from_bic(bic_dict['OLS_uni']['bic'], bic_dict['OLS_full']['bic'])\n",
    "        report.append(f\"\\nBayes Factor (uni over full) ≈ {bf_val:.3g}\")\n",
    "report.append(\"\\nSTATISTICAL TESTS\")\n",
    "# add p-values from previous step (quick)\n",
    "report.append(\"See printed p-values above (t-test and Wilcoxon) for pairwise comparisons between UNI and each multi model.\")\n",
    "report.append(\"\\nCONCLUSION\")\n",
    "report.append(\"Choose model balancing predictive performance, statistical significance (p-values), and Bayes Factor (BIC based).\")\n",
    "\n",
    "print(\"\\n\\n\".join(report))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
